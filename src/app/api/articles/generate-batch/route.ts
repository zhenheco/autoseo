import { NextRequest, NextResponse } from "next/server";
import { createClient, createAdminClient } from "@/lib/supabase/server";
import { v4 as uuidv4 } from "uuid";
import slugify from "slugify";

// Vercel ç„¡ä¼ºæœå™¨å‡½æ•¸æœ€å¤§åŸ·è¡Œæ™‚é–“ï¼ˆç•°æ­¥æ¨¡å¼ï¼šç«‹å³è¿”å›ï¼Œç„¡éœ€é•·æ™‚é–“åŸ·è¡Œï¼‰
export const maxDuration = 10; // 10 ç§’è¶³å¤ ï¼ˆå¯¦éš› < 1 ç§’ï¼‰

export async function POST(request: NextRequest) {
  try {
    const body = await request.json();
    const { keywords, items, options, website_id } = body;
    const hasWebsiteIdField = "website_id" in body;

    const generationItems =
      items ||
      keywords?.map((kw: string) => ({ keyword: kw, title: kw })) ||
      [];

    if (!generationItems || generationItems.length === 0) {
      return NextResponse.json(
        { error: "Items or keywords array is required" },
        { status: 400 },
      );
    }

    const supabase = await createClient();
    const {
      data: { user },
    } = await supabase.auth.getUser();

    if (!user) {
      return NextResponse.json({ error: "Unauthorized" }, { status: 401 });
    }

    // ä½¿ç”¨ Admin Client ç¹é RLS é€²è¡Œå…¬å¸/æˆå“¡æ“ä½œ
    const adminClient = createAdminClient();

    // å˜—è©¦ç²å– company_idï¼ˆå¦‚æœç”¨æˆ¶æœ‰åŠ å…¥å…¬å¸ï¼‰
    const { data: membership } = await adminClient
      .from("company_members")
      .select("company_id")
      .eq("user_id", user.id)
      .eq("status", "active")
      .single();

    let billingId: string | undefined = membership?.company_id;

    // é©—è­‰ company_id æ˜¯å¦çœŸçš„å­˜åœ¨æ–¼ companies è¡¨
    if (billingId) {
      const { data: companyExists } = await adminClient
        .from("companies")
        .select("id")
        .eq("id", billingId)
        .single();

      if (!companyExists) {
        console.log(
          `[Batch] âš ï¸ Company ${billingId} not found, will create new one`,
        );
        billingId = undefined;
      }
    }

    // å¦‚æœæ²’æœ‰æœ‰æ•ˆçš„å…¬å¸ï¼Œæª¢æŸ¥æ˜¯å¦å·²æœ‰ç”¨æˆ¶æ“æœ‰çš„å…¬å¸æˆ–è‡ªå‹•å‰µå»ºå€‹äººå…¬å¸
    if (!billingId) {
      const { data: existingCompany } = await adminClient
        .from("companies")
        .select("id")
        .eq("owner_id", user.id)
        .single();

      if (existingCompany) {
        billingId = existingCompany.id;
      } else {
        // å‰µå»ºå€‹äººå…¬å¸ï¼ˆä½¿ç”¨ Admin Client ç¹é RLSï¼‰
        const baseSlug = slugify(user.email?.split("@")[0] || "user", {
          lower: true,
          strict: true,
        });
        const uniqueSlug = `${baseSlug}-${Date.now()}`;

        const { data: newCompany, error: companyError } = await adminClient
          .from("companies")
          .insert({
            name: user.email?.split("@")[0] || "å€‹äººç”¨æˆ¶",
            slug: uniqueSlug,
            owner_id: user.id,
          })
          .select("id")
          .single();

        if (companyError || !newCompany) {
          console.error("[Batch] Failed to create company:", companyError);
          return NextResponse.json(
            { error: "ç„¡æ³•å»ºç«‹ç”¨æˆ¶å¸³æˆ¶", details: companyError?.message },
            { status: 500 },
          );
        }

        billingId = newCompany.id;
        console.log(`[Batch] âœ… Created company: ${billingId}`);
      }

      // æ›´æ–°æˆ–å‰µå»º company_members è¨˜éŒ„ï¼ˆä½¿ç”¨ Admin Clientï¼‰
      const { error: memberError } = await adminClient
        .from("company_members")
        .upsert(
          {
            company_id: billingId,
            user_id: user.id,
            role: "owner",
            status: "active",
          },
          {
            onConflict: "company_id,user_id",
          },
        );

      if (memberError) {
        console.error("[Batch] Failed to upsert member:", memberError);
      }
    }

    // è™•ç† website_idï¼š
    // - å¦‚æœ body ä¸­åŒ…å« website_id æ¬„ä½ï¼ˆå³ä½¿æ˜¯ nullï¼‰ï¼Œå‰‡ä½¿ç”¨è©²å€¼
    // - å¦‚æœ body ä¸­æ²’æœ‰ website_id æ¬„ä½ï¼Œå‰‡è‡ªå‹•æŸ¥è©¢æˆ–å‰µå»ºç¶²ç«™
    let websiteId: string | null = website_id || null;

    if (hasWebsiteIdField) {
      if (websiteId) {
        console.log("[Batch] ä½¿ç”¨æŒ‡å®šç¶²ç«™:", websiteId);
      } else {
        console.log("[Batch] ç”¨æˆ¶é¸æ“‡ä¸æŒ‡å®šç¶²ç«™");
      }
    } else {
      const websiteQuery = await adminClient
        .from("website_configs")
        .select("id")
        .eq("company_id", billingId)
        .limit(1);

      let websites = websiteQuery.data;
      const websiteError = websiteQuery.error;

      if ((!websites || websites.length === 0) && !websiteError) {
        console.log("[Batch] Creating default website config for:", billingId);
        const { data: newWebsite, error: createError } = await adminClient
          .from("website_configs")
          .insert({
            company_id: billingId,
            website_name: "",
            wordpress_url: "",
          })
          .select("id")
          .single();

        if (createError || !newWebsite) {
          console.error(
            "[Batch] Failed to create website config:",
            createError,
          );
          return NextResponse.json(
            {
              error: "Failed to create website configuration",
              details: createError?.message,
            },
            { status: 500 },
          );
        }

        const { error: agentConfigError } = await adminClient
          .from("agent_configs")
          .insert({
            website_id: newWebsite.id,
            research_model: "deepseek-reasoner",
            complex_processing_model: "deepseek-reasoner",
            simple_processing_model: "deepseek-chat",
            image_model: "gemini-imagen",
            research_temperature: 0.7,
            research_max_tokens: 64000,
            strategy_temperature: 0.7,
            strategy_max_tokens: 64000,
            writing_temperature: 0.7,
            writing_max_tokens: 64000,
            image_size: "1024x1024",
            image_count: 3,
            meta_enabled: true,
            meta_temperature: 0.7,
            meta_max_tokens: 64000,
          });

        if (agentConfigError) {
          console.error(
            "[Batch] Failed to create agent config:",
            agentConfigError,
          );
          return NextResponse.json(
            {
              error: "Failed to create agent configuration",
              details: agentConfigError.message,
            },
            { status: 500 },
          );
        }

        websites = [newWebsite];
      }

      if (!websites || websites.length === 0) {
        console.error("[Batch] Website error:", websiteError);
        return NextResponse.json(
          { error: "No website configured" },
          { status: 404 },
        );
      }

      websiteId = websites[0].id;
      console.log("[Batch] è‡ªå‹•ä½¿ç”¨ç¾æœ‰ç¶²ç«™é…ç½®:", websiteId);
    }

    const newJobIds: string[] = [];
    const skippedJobIds: string[] = [];
    const failedItems: string[] = [];

    // æ‰¹æ¬¡ç”Ÿæˆæ¨¡å¼ï¼šç›´æ¥åŸ·è¡Œï¼Œå¯¦ä½œå†ªç­‰æ€§æª¢æŸ¥
    for (const item of generationItems) {
      const keyword = item.keyword || item.title;
      const title = item.title || item.keyword;

      // æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒé—œéµå­—çš„ pending/processing ä»»å‹™
      const { data: existingJobs } = await adminClient
        .from("article_jobs")
        .select("id, status, keywords")
        .eq("company_id", billingId)
        .contains("keywords", [keyword])
        .in("status", ["pending", "processing"])
        .order("created_at", { ascending: false })
        .limit(1);

      // å¦‚æœå­˜åœ¨æœªå®Œæˆçš„ä»»å‹™ï¼Œè·³éå‰µå»ºä¸¦è¨˜éŒ„ ID
      if (existingJobs && existingJobs.length > 0) {
        const existingJob = existingJobs[0];
        skippedJobIds.push(existingJob.id);
        console.log(
          `[Batch] â­ï¸  Skipping duplicate job: ${title} (existing: ${existingJob.id}, status: ${existingJob.status})`,
        );
        continue;
      }

      // å‰µå»ºæ–°ä»»å‹™
      const articleJobId = uuidv4();

      const { error: jobError } = await adminClient
        .from("article_jobs")
        .insert({
          id: articleJobId,
          job_id: articleJobId,
          company_id: billingId,
          website_id: websiteId,
          user_id: user.id,
          keywords: [keyword],
          status: "pending",
          metadata: {
            mode: "batch",
            title,
            batchIndex: generationItems.indexOf(item),
            totalBatch: generationItems.length,
            targetLanguage: options?.targetLanguage || "zh-TW",
            wordCount: options?.wordCount || "1500",
          },
        });

      if (jobError) {
        console.error("[Batch] Failed to create article job:", jobError);
        failedItems.push(title);
        continue;
      }

      newJobIds.push(articleJobId);
      console.log(`[Batch] âœ… Article job queued: ${title}`);
    }

    // åˆä½µæ‰€æœ‰ job IDï¼ˆæ–°å»ºç«‹ + è·³éçš„ï¼‰
    const allJobIds = [...newJobIds, ...skippedJobIds];

    // åªæœ‰æ–°å»ºç«‹çš„ job æ‰éœ€è¦è§¸ç™¼ GitHub Actions
    if (newJobIds.length > 0) {
      try {
        const githubToken = process.env.GITHUB_TOKEN;
        const githubOwner = process.env.GITHUB_REPO_OWNER;
        const githubRepo = process.env.GITHUB_REPO_NAME;

        if (githubToken && githubOwner && githubRepo) {
          const maxRetries = 3;
          let lastError: string | null = null;
          let success = false;

          for (let attempt = 1; attempt <= maxRetries; attempt++) {
            try {
              const response = await fetch(
                `https://api.github.com/repos/${githubOwner}/${githubRepo}/dispatches`,
                {
                  method: "POST",
                  headers: {
                    Authorization: `Bearer ${githubToken}`,
                    Accept: "application/vnd.github.v3+json",
                    "Content-Type": "application/json",
                  },
                  body: JSON.stringify({
                    event_type: "article-jobs-created",
                    client_payload: {
                      jobCount: newJobIds.length,
                      jobIds: newJobIds,
                      timestamp: new Date().toISOString(),
                    },
                  }),
                },
              );

              if (response.ok) {
                console.log(
                  `[Batch] âœ… Triggered GitHub Actions workflow for ${newJobIds.length} jobs (attempt ${attempt})`,
                );
                success = true;
                break;
              } else {
                lastError = await response.text();
                console.warn(
                  `[Batch] âš ï¸  Workflow trigger attempt ${attempt}/${maxRetries} failed:`,
                  response.status,
                  lastError,
                );

                if (attempt < maxRetries) {
                  await new Promise((resolve) =>
                    setTimeout(resolve, 1000 * attempt),
                  );
                }
              }
            } catch (fetchError) {
              lastError =
                fetchError instanceof Error
                  ? fetchError.message
                  : String(fetchError);
              console.warn(
                `[Batch] âš ï¸  Workflow trigger attempt ${attempt}/${maxRetries} error:`,
                lastError,
              );

              if (attempt < maxRetries) {
                await new Promise((resolve) =>
                  setTimeout(resolve, 1000 * attempt),
                );
              }
            }
          }

          if (!success) {
            console.error(
              `[Batch] âŒ Failed to trigger workflow after ${maxRetries} attempts. Deleting jobs...`,
              lastError,
            );

            for (const jobId of newJobIds) {
              try {
                await supabase.from("article_jobs").delete().eq("id", jobId);
                console.log(`[Batch] ğŸ—‘ï¸  Deleted failed job: ${jobId}`);
              } catch (deleteError) {
                console.error(
                  `[Batch] âŒ Failed to delete job ${jobId}:`,
                  deleteError,
                );
              }
            }

            return NextResponse.json(
              {
                success: false,
                error: `GitHub Actions è§¸ç™¼å¤±æ•—ï¼ˆé‡è©¦ ${maxRetries} æ¬¡å¾Œä»å¤±æ•—ï¼‰ï¼Œå·²æ¸…é™¤å¾…è™•ç†ä»»å‹™`,
                details: lastError,
              },
              { status: 503 },
            );
          }
        } else {
          console.log(
            "[Batch] âš ï¸  GitHub configuration incomplete (GITHUB_TOKEN, GITHUB_REPO_OWNER, or GITHUB_REPO_NAME missing), workflow will run on schedule",
          );
        }
      } catch (dispatchError) {
        console.error("[Batch] âš ï¸  Error triggering workflow:", dispatchError);
      }
    }

    // åˆ¤æ–·æ˜¯å¦æˆåŠŸï¼šè‡³å°‘è¦æœ‰æ–°å»ºç«‹çš„ job æˆ–è·³éçš„ jobï¼ˆä»£è¡¨ä»»å‹™å·²åœ¨è™•ç†ä¸­ï¼‰
    const hasJobs = allJobIds.length > 0;
    const allFailed =
      failedItems.length > 0 &&
      newJobIds.length === 0 &&
      skippedJobIds.length === 0;

    if (allFailed) {
      return NextResponse.json(
        {
          success: false,
          error: "æ‰€æœ‰æ–‡ç« ä»»å‹™å»ºç«‹å¤±æ•—",
          failedItems,
        },
        { status: 500 },
      );
    }

    return NextResponse.json({
      success: hasJobs,
      jobIds: allJobIds,
      newJobs: newJobIds.length,
      skippedJobs: skippedJobIds.length,
      failedJobs: failedItems.length,
      failedItems,
      message:
        newJobIds.length > 0
          ? `å·²å»ºç«‹ ${newJobIds.length} å€‹æ–°ä»»å‹™${skippedJobIds.length > 0 ? `ï¼Œ${skippedJobIds.length} å€‹å·²åœ¨è™•ç†ä¸­` : ""}`
          : `${skippedJobIds.length} å€‹ä»»å‹™å·²åœ¨è™•ç†ä¸­`,
      polling: {
        statusUrl: "/api/articles/status/[jobId]",
        recommendedInterval: 60000,
      },
    });
  } catch (error) {
    console.error("Batch generate error:", error);
    return NextResponse.json(
      { error: "Internal server error", details: (error as Error).message },
      { status: 500 },
    );
  }
}
