#!/usr/bin/env tsx

/**
 * æ–‡ç« ç”Ÿæˆä»»å‹™è™•ç†è…³æœ¬
 *
 * ğŸ”§ å„ªåŒ–ï¼š
 * - Redis flag æª¢æŸ¥ï¼šæ²’æœ‰ä»»å‹™æ™‚è·³éè³‡æ–™åº«æŸ¥è©¢
 * - ç²¾ç°¡ select æ¬„ä½ï¼šæ¸›å°‘æ•¸æ“šå‚³è¼¸é‡
 * - å®Œæ•´ fallbackï¼šRedis å¤±æ•—æ™‚é™ç´šåˆ°è³‡æ–™åº«æŸ¥è©¢
 */

import { createClient } from "@supabase/supabase-js";
import { ParallelOrchestrator } from "../src/lib/agents/orchestrator";
import {
  cacheGet,
  cacheSet,
  cacheDelete,
  isRedisAvailable,
} from "../src/lib/cache/redis-cache";
import type { Database } from "../src/types/database.types";

const MAX_RETRIES = 2;
const CACHE_KEY_PENDING_ARTICLE = "jobs:pending:article";

/**
 * åˆ¤æ–·éŒ¯èª¤æ˜¯å¦å¯é‡è©¦
 * ä¸å¯é‡è©¦çš„éŒ¯èª¤åŒ…æ‹¬ï¼šèªè­‰éŒ¯èª¤ã€ç„¡æ•ˆè«‹æ±‚ç­‰
 */
function isRetryableJobError(errorMessage: string): boolean {
  const nonRetryablePatterns = [
    "Invalid API key",
    "Unauthorized",
    "invalid_request",
    "company_id is required",
    "website_id is required",
  ];
  return !nonRetryablePatterns.some((p) =>
    errorMessage.toLowerCase().includes(p.toLowerCase()),
  );
}

async function main() {
  const supabase = createClient<Database>(
    process.env.SUPABASE_URL!,
    process.env.SUPABASE_SERVICE_ROLE_KEY!,
    {
      auth: {
        autoRefreshToken: false,
        persistSession: false,
      },
    },
  );

  // ========== ğŸ”§ å„ªåŒ–ï¼šå…ˆæª¢æŸ¥ Redis flag ==========
  let shouldQueryDb = true;
  if (isRedisAvailable()) {
    try {
      const hasPendingJobs = await cacheGet<boolean>(CACHE_KEY_PENDING_ARTICLE);
      if (hasPendingJobs === false) {
        console.log(
          "[Process Jobs] âœ… Redis é¡¯ç¤ºæ²’æœ‰å¾…è™•ç†ä»»å‹™ï¼Œè·³éè³‡æ–™åº«æŸ¥è©¢",
        );
        shouldQueryDb = false;
      }
      // hasPendingJobs === null (key ä¸å­˜åœ¨) â†’ ä¿å®ˆè™•ç†ï¼ŒæŸ¥è©¢è³‡æ–™åº«
    } catch (error) {
      console.warn("[Process Jobs] âš ï¸ Redis æª¢æŸ¥å¤±æ•—ï¼Œfallback åˆ°è³‡æ–™åº«æŸ¥è©¢");
    }
  }

  // é˜²å‘†ï¼šæ¯ 30 åˆ†é˜å¼·åˆ¶æª¢æŸ¥ä¸€æ¬¡è³‡æ–™åº«
  if (!shouldQueryDb) {
    const currentMinute = new Date().getMinutes();
    if (currentMinute % 30 === 0) {
      console.log("[Process Jobs] ğŸ”„ å®šæœŸå¼·åˆ¶æª¢æŸ¥è³‡æ–™åº«");
      shouldQueryDb = true;
    }
  }

  if (!shouldQueryDb) {
    return;
  }

  console.log("[Process Jobs] ğŸ” æŸ¥è©¢å¾…è™•ç†ä»»å‹™...");

  const threeMinutesAgo = new Date(Date.now() - 3 * 60 * 1000).toISOString();

  // ========== ğŸ”§ å„ªåŒ–ï¼šç²¾ç°¡ select æ¬„ä½ ==========
  // åªæŸ¥è©¢ orchestrator.execute() éœ€è¦çš„æ¬„ä½
  const { data: jobs, error } = await supabase
    .from("article_jobs")
    .select(
      `
      id,
      company_id,
      website_id,
      status,
      keywords,
      metadata,
      started_at,
      created_at
    `,
    )
    .in("status", ["pending", "processing"])
    .or(`started_at.is.null,started_at.lt.${threeMinutesAgo}`)
    .order("created_at", { ascending: true })
    .limit(20); // æœ€å¤šåŒæ™‚è™•ç† 20 å€‹ä»»å‹™

  if (error) {
    console.error("[Process Jobs] âŒ æŸ¥è©¢å¤±æ•—:", error);
    process.exit(1);
  }

  if (!jobs || jobs.length === 0) {
    console.log("[Process Jobs] âœ… æ²’æœ‰å¾…è™•ç†ä»»å‹™");
    // æ›´æ–° Redis flagï¼šç¢ºå®šæ²’æœ‰ä»»å‹™
    if (isRedisAvailable()) {
      await cacheSet(CACHE_KEY_PENDING_ARTICLE, false, 300).catch(() => {});
    }
    return;
  }

  console.log(`[Process Jobs] ğŸ”„ ç™¼ç¾ ${jobs.length} å€‹ä»»å‹™`);
  console.log(`[Process Jobs] âš¡ ä½¿ç”¨ä¸¦è¡Œè™•ç†æ¨¡å¼`);

  // ä¸¦è¡Œè™•ç†æ‰€æœ‰ä»»å‹™
  const processPromises = jobs.map(async (job) => {
    console.log(`[Process Jobs] ğŸ”’ å˜—è©¦é–å®šä»»å‹™ ${job.id}`);

    // ç”Ÿæˆå”¯ä¸€çš„é–å®šæ™‚é–“æˆ³
    const lockTimestamp = new Date().toISOString();

    // Step 1: å˜—è©¦æ›´æ–°ï¼ˆä½¿ç”¨æ¨‚è§€é–å®šæ¢ä»¶ï¼‰
    // æ³¨æ„ï¼šä¸ä½¿ç”¨ .select()ï¼Œå› ç‚º Supabase æœƒé‡æ–°å¥—ç”¨ .or() æ¢ä»¶å°è‡´ç©ºçµæœ
    const { error: lockError } = await supabase
      .from("article_jobs")
      .update({
        status: "processing",
        started_at: lockTimestamp,
      })
      .eq("id", job.id)
      .in("status", ["pending", "processing"])
      .or(`started_at.is.null,started_at.lt.${threeMinutesAgo}`);

    if (lockError) {
      console.log(
        `[Process Jobs] âŒ é–å®šä»»å‹™å¤±æ•— ${job.id}: ${lockError.message}`,
      );
      return { success: false, jobId: job.id };
    }

    // Step 2: é©—è­‰æ˜¯å¦æˆåŠŸå–å¾—é–å®šï¼ˆæª¢æŸ¥ started_at æ˜¯å¦ç‚ºæˆ‘å€‘è¨­å®šçš„å€¼ï¼‰
    // ğŸ”§ å„ªåŒ–ï¼šåªéœ€è¦ id æ¬„ä½é©—è­‰é–å®š
    const { data: locked } = await supabase
      .from("article_jobs")
      .select("id")
      .eq("id", job.id)
      .eq("started_at", lockTimestamp)
      .single();

    if (!locked) {
      console.log(`[Process Jobs] â­ï¸  ä»»å‹™ ${job.id} å·²è¢«å…¶ä»–ç¨‹åºè™•ç†ï¼Œè·³é`);
      return { success: false, jobId: job.id };
    }

    console.log(`[Process Jobs] âœ… æˆåŠŸé–å®šä»»å‹™ ${job.id}`);

    try {
      const orchestrator = new ParallelOrchestrator(supabase);
      const metadata = job.metadata as Record<string, unknown> | null;
      const title =
        (metadata?.title as string) || job.keywords?.[0] || "Untitled";

      console.log(`[Process Jobs] ğŸš€ é–‹å§‹è™•ç†ä»»å‹™ ${job.id} - ${title}`);

      await orchestrator.execute({
        articleJobId: job.id,
        companyId: job.company_id,
        websiteId: job.website_id,
        title: title,
        targetLanguage: metadata?.targetLanguage as string | undefined,
        language: metadata?.language as string | undefined,
        region: metadata?.region as string | undefined,
        industry: metadata?.industry as string | null | undefined,
        wordCount:
          typeof metadata?.wordCount === "string"
            ? parseInt(metadata.wordCount)
            : (metadata?.wordCount as number | undefined),
        imageCount:
          typeof metadata?.imageCount === "string"
            ? parseInt(metadata.imageCount)
            : (metadata?.imageCount as number | undefined),
      });

      console.log(`[Process Jobs] âœ… ä»»å‹™ ${job.id} è™•ç†æˆåŠŸ`);

      // æ–‡ç« ç”Ÿæˆå®Œæˆå¾Œï¼Œæª¢æŸ¥æ˜¯å¦è¦è‡ªå‹•æ’ç¨‹
      if (job.website_id) {
        try {
          const { autoScheduleArticle } = await import(
            "../src/lib/scheduling/auto-schedule"
          );
          const scheduleResult = await autoScheduleArticle(
            supabase,
            job.id,
            job.website_id,
          );

          if (scheduleResult.success) {
            console.log(
              `[Process Jobs] ğŸ“… å·²è‡ªå‹•æ’ç¨‹åˆ° ${scheduleResult.scheduledAt}`,
            );
          } else {
            console.log(
              `[Process Jobs] â­ï¸  è‡ªå‹•æ’ç¨‹è·³é: ${scheduleResult.error}`,
            );
          }
        } catch (scheduleErr) {
          // è‡ªå‹•æ’ç¨‹å¤±æ•—ä¸å½±éŸ¿æ–‡ç« ç”Ÿæˆçµæœ
          console.error(`[Process Jobs] âš ï¸ è‡ªå‹•æ’ç¨‹éŒ¯èª¤:`, scheduleErr);
        }
      }

      return { success: true, jobId: job.id };
    } catch (err) {
      console.error(`[Process Jobs] âŒ ä»»å‹™ ${job.id} å¤±æ•—:`, err);

      const currentMetadata = (job.metadata as Record<string, unknown>) || {};
      const retryCount = (currentMetadata.retry_count as number) || 0;
      const errorMessage = err instanceof Error ? err.message : String(err);

      // æª¢æŸ¥æ˜¯å¦å¯é‡è©¦ä¸”æœªè¶…éæœ€å¤§é‡è©¦æ¬¡æ•¸
      if (isRetryableJobError(errorMessage) && retryCount < MAX_RETRIES) {
        console.log(
          `[Process Jobs] ğŸ”„ æ’ç¨‹é‡è©¦ ${retryCount + 1}/${MAX_RETRIES} - ä»»å‹™ ${job.id}`,
        );
        await supabase
          .from("article_jobs")
          .update({
            status: "pending",
            started_at: null,
            metadata: {
              ...currentMetadata,
              retry_count: retryCount + 1,
              last_error: errorMessage,
              last_retry_at: new Date().toISOString(),
            },
          })
          .eq("id", job.id);
      } else {
        // ä¸å¯é‡è©¦æˆ–å·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸ï¼Œæ¨™è¨˜ç‚ºå¤±æ•—
        const reason = !isRetryableJobError(errorMessage)
          ? "ä¸å¯é‡è©¦çš„éŒ¯èª¤"
          : `å·²é‡è©¦ ${retryCount} æ¬¡`;
        console.log(`[Process Jobs] âŒ ä»»å‹™ ${job.id} æ¨™è¨˜ç‚ºå¤±æ•—ï¼ˆ${reason}ï¼‰`);
        await supabase
          .from("article_jobs")
          .update({
            status: "failed",
            metadata: {
              ...currentMetadata,
              error: errorMessage,
              failed_at: new Date().toISOString(),
              retry_count: retryCount,
            },
          })
          .eq("id", job.id);
      }

      return { success: false, jobId: job.id };
    }
  });

  // ç­‰å¾…æ‰€æœ‰ä»»å‹™å®Œæˆ
  const results = await Promise.all(processPromises);
  const successCount = results.filter((r) => r.success).length;
  const failedCount = results.filter((r) => !r.success).length;

  console.log(
    `[Process Jobs] ğŸ“Š è™•ç†çµæœï¼š${successCount} æˆåŠŸï¼Œ${failedCount} å¤±æ•—`,
  );
  results.forEach((result) => {
    console.log(`  - ${result.jobId}: ${result.success ? "âœ…" : "âŒ"}`);
  });

  // ========== ğŸ”§ å„ªåŒ–ï¼šæ›´æ–° Redis flag ==========
  if (isRedisAvailable()) {
    try {
      // æª¢æŸ¥æ˜¯å¦é‚„æœ‰å…¶ä»–å¾…è™•ç†ä»»å‹™
      const { count: remainingCount } = await supabase
        .from("article_jobs")
        .select("id", { count: "exact", head: true })
        .eq("status", "pending");

      if (remainingCount === 0) {
        // æ²’æœ‰å‰©é¤˜ä»»å‹™ï¼Œè¨­ç½® flag ç‚º false
        await cacheSet(CACHE_KEY_PENDING_ARTICLE, false, 300);
        console.log("[Process Jobs] âœ… Redis flag å·²è¨­ç‚º falseï¼ˆç„¡å‰©é¤˜ä»»å‹™ï¼‰");
      } else {
        // é‚„æœ‰ä»»å‹™ï¼Œåˆ·æ–° TTL
        await cacheSet(CACHE_KEY_PENDING_ARTICLE, true, 300);
        console.log(
          `[Process Jobs] â„¹ï¸ é‚„æœ‰ ${remainingCount} å€‹å¾…è™•ç†ä»»å‹™ï¼Œåˆ·æ–° Redis flag`,
        );
      }
    } catch {
      // Redis æ›´æ–°å¤±æ•—ä¸å½±éŸ¿ä¸»æµç¨‹
      console.warn("[Process Jobs] âš ï¸ Redis flag æ›´æ–°å¤±æ•—ï¼Œå¿½ç•¥");
    }
  }

  console.log("[Process Jobs] ğŸ‰ æ‰€æœ‰ä»»å‹™è™•ç†å®Œæˆ");
}

main().catch((err) => {
  console.error("[Process Jobs] âŒ Fatal error:", err);
  process.exit(1);
});
