# ä¿®å¾©å¤š Agent æ¶æ§‹çš„æ–‡ç« å„²å­˜å’ŒéŒ¯èª¤è¿½è¹¤

> **å®Œæ•´å¯¦ä½œæŒ‡å—** - å·¥ç¨‹å¸«å¯ç¨ç«‹å®Œæˆ

---

## ğŸ“‹ å¿«é€Ÿé–‹å§‹

### å•é¡Œæ¦‚è¿°

ç•¶å‰å¤š Agent æ–‡ç« ç”Ÿæˆæ¶æ§‹å­˜åœ¨ä»¥ä¸‹å•é¡Œï¼š

1. âœ… **å·²ç¢ºèª**ï¼šæ–‡ç« ç”Ÿæˆå®Œæˆä½†æœªå„²å­˜åˆ°è³‡æ–™åº«
2. âœ… **å·²ç¢ºèª**ï¼š`ContentAssemblerAgent` è¼¸å‡ºæ ¼å¼ç¼ºå°‘ 3 å€‹æ¬„ä½
3. âœ… **å·²ç¢ºèª**ï¼šéŒ¯èª¤è¨Šæ¯ç¼ºå¤±æˆ–ä¸å®Œæ•´

### è§£æ±ºæ–¹æ¡ˆ

1. **Output Adapter**ï¼šè½‰æ›æ ¼å¼ï¼Œè£œå……ç¼ºå¤±çš„æ¬„ä½
2. **Error Tracker**ï¼šå¼·åŒ–éŒ¯èª¤è¿½è¹¤ï¼Œå¯«å…¥è³‡æ–™åº«
3. **State Management**ï¼šå®Œå–„ç‹€æ…‹ä¿å­˜å’Œæ¢å¾©
4. **Monitoring**ï¼šGitHub Actions å®šæœŸç›£æ§

---

## ğŸš€ å¯¦ä½œæ­¥é©Ÿ

### Phase 1: æ ¸å¿ƒæ¶æ§‹ï¼ˆDay 1-2ï¼‰

#### Step 1.1: å»ºç«‹ Output Adapter

**å»ºç«‹æª”æ¡ˆ**ï¼š`src/lib/agents/output-adapter.ts`

```typescript
/**
 * Multi-Agent Output Adapter
 * å°‡ ContentAssembler è¼¸å‡ºè½‰æ›ç‚º WritingAgent æ¨™æº–æ ¼å¼
 */

import type {
  ContentAssemblerOutput,
  StrategyAgentOutput,
  WritingAgentOutput,
} from "@/types/agents";

export interface AdapterInput {
  assemblerOutput: ContentAssemblerOutput;
  strategyOutput: StrategyAgentOutput;
  focusKeyword: string;
}

interface ReadabilityMetrics {
  fleschReadingEase: number;
  fleschKincaidGrade: number;
  gunningFogIndex: number;
}

interface KeywordUsage {
  count: number;
  density: number;
  positions?: number[];
}

interface InternalLink {
  url: string;
  title: string;
  anchor: string;
}

export class MultiAgentOutputAdapter {
  adapt(input: AdapterInput): WritingAgentOutput {
    const { assemblerOutput, strategyOutput, focusKeyword } = input;

    // è£œå……ç¼ºå¤±çš„æ¬„ä½
    const readability = this.calculateReadability(assemblerOutput.markdown);
    const keywordUsage = this.analyzeKeywordUsage(
      assemblerOutput.markdown,
      focusKeyword,
    );
    const internalLinks = this.extractInternalLinks(assemblerOutput.html);

    return {
      markdown: assemblerOutput.markdown,
      html: assemblerOutput.html,
      statistics: {
        ...assemblerOutput.statistics,
        readingTime: this.calculateReadingTime(
          assemblerOutput.statistics.totalWords,
        ),
        sentenceCount: this.countSentences(assemblerOutput.markdown),
        wordCount: assemblerOutput.statistics.totalWords,
        paragraphCount: assemblerOutput.statistics.totalParagraphs,
      },
      readability,
      keywordUsage,
      internalLinks,
      executionInfo: assemblerOutput.executionInfo,
    };
  }

  private calculateReadability(markdown: string): ReadabilityMetrics {
    // ç§»é™¤ Markdown èªæ³•
    const plainText = markdown
      .replace(/!\[.*?\]\(.*?\)/g, "") // ç§»é™¤åœ–ç‰‡
      .replace(/\[([^\]]+)\]\([^\)]+\)/g, "$1") // ç§»é™¤é€£çµï¼Œä¿ç•™æ–‡å­—
      .replace(/[#*`_~]/g, "") // ç§»é™¤æ ¼å¼ç¬¦è™Ÿ
      .trim();

    const sentences = this.getSentences(plainText);
    const words = this.getWords(plainText);
    const syllables = this.countSyllables(words);

    // Flesch Reading Ease: 206.835 - 1.015(words/sentences) - 84.6(syllables/words)
    const fleschReadingEase = Math.max(
      0,
      Math.min(
        100,
        206.835 -
          1.015 * (words.length / Math.max(sentences.length, 1)) -
          84.6 * (syllables / Math.max(words.length, 1)),
      ),
    );

    // Flesch-Kincaid Grade Level: 0.39(words/sentences) + 11.8(syllables/words) - 15.59
    const fleschKincaidGrade = Math.max(
      0,
      0.39 * (words.length / Math.max(sentences.length, 1)) +
        11.8 * (syllables / Math.max(words.length, 1)) -
        15.59,
    );

    // Gunning Fog Index: 0.4 * ((words/sentences) + 100 * (complex_words/words))
    const complexWords = words.filter(
      (word) => this.syllableCount(word) > 2,
    ).length;
    const gunningFogIndex = Math.max(
      0,
      0.4 *
        (words.length / Math.max(sentences.length, 1) +
          100 * (complexWords / Math.max(words.length, 1))),
    );

    return {
      fleschReadingEase: Math.round(fleschReadingEase * 10) / 10,
      fleschKincaidGrade: Math.round(fleschKincaidGrade * 10) / 10,
      gunningFogIndex: Math.round(gunningFogIndex * 10) / 10,
    };
  }

  private getSentences(text: string): string[] {
    return text
      .split(/[.!?]+/)
      .map((s) => s.trim())
      .filter((s) => s.length > 0);
  }

  private getWords(text: string): string[] {
    return text
      .toLowerCase()
      .split(/\s+/)
      .filter((w) => w.length > 0 && /[a-z]/.test(w));
  }

  private countSyllables(words: string[]): number {
    return words.reduce((total, word) => total + this.syllableCount(word), 0);
  }

  private syllableCount(word: string): number {
    word = word.toLowerCase();
    if (word.length <= 3) return 1;

    word = word.replace(/(?:[^laeiouy]es|ed|[^laeiouy]e)$/, "");
    word = word.replace(/^y/, "");

    const matches = word.match(/[aeiouy]{1,2}/g);
    return matches ? matches.length : 1;
  }

  private analyzeKeywordUsage(markdown: string, keyword: string): KeywordUsage {
    const lowerText = markdown.toLowerCase();
    const lowerKeyword = keyword.toLowerCase();

    // è¨ˆç®—å‡ºç¾æ¬¡æ•¸
    const regex = new RegExp(`\\b${lowerKeyword}\\b`, "gi");
    const matches = lowerText.match(regex);
    const count = matches ? matches.length : 0;

    // è¨ˆç®—å¯†åº¦
    const words = this.getWords(markdown);
    const density = words.length > 0 ? (count / words.length) * 100 : 0;

    return {
      count,
      density: Math.round(density * 100) / 100,
    };
  }

  private extractInternalLinks(html: string): InternalLink[] {
    const links: InternalLink[] = [];
    const regex = /<a\s+(?:[^>]*?\s+)?href=["']([^"']*)["'][^>]*>(.*?)<\/a>/gi;

    let match;
    while ((match = regex.exec(html)) !== null) {
      const url = match[1];
      const anchor = match[2].replace(/<[^>]+>/g, "").trim();

      // åªä¿ç•™å…§éƒ¨é€£çµï¼ˆç›¸å°è·¯å¾‘æˆ–åŒåŸŸåï¼‰
      if (url.startsWith("/") || url.startsWith("#") || !url.includes("://")) {
        links.push({
          url,
          title: anchor,
          anchor,
        });
      }
    }

    return links;
  }

  private calculateReadingTime(wordCount: number): number {
    // å‡è¨­é–±è®€é€Ÿåº¦ï¼šæ¯åˆ†é˜ 200 å­—
    return Math.ceil(wordCount / 200);
  }

  private countSentences(markdown: string): number {
    const plainText = markdown.replace(/[#*`_~]/g, "").trim();
    return this.getSentences(plainText).length;
  }
}
```

**æª¢æŸ¥æ¸…å–®**ï¼š

- [ ] æª”æ¡ˆå»ºç«‹å®Œæˆ
- [ ] æ‰€æœ‰æ–¹æ³•éƒ½å¯¦ä½œ
- [ ] TypeScript ç„¡éŒ¯èª¤

---

#### Step 1.2: æ›´æ–°å‹åˆ¥å®šç¾©

**ä¿®æ”¹æª”æ¡ˆ**ï¼š`src/types/agents.ts`

åœ¨æª”æ¡ˆæœ«å°¾åŠ å…¥ï¼š

```typescript
// Output Adapter ç›¸é—œå‹åˆ¥
export interface AdapterInput {
  assemblerOutput: ContentAssemblerOutput;
  strategyOutput: StrategyAgentOutput;
  focusKeyword: string;
}

export interface ReadabilityMetrics {
  fleschReadingEase: number;
  fleschKincaidGrade: number;
  gunningFogIndex: number;
}

export interface KeywordUsage {
  count: number;
  density: number;
  positions?: number[];
}

export interface InternalLink {
  url: string;
  title: string;
  anchor: string;
}
```

**æª¢æŸ¥æ¸…å–®**ï¼š

- [ ] å‹åˆ¥å®šç¾©å·²åŠ å…¥
- [ ] TypeScript ç„¡éŒ¯èª¤

---

#### Step 1.3: æ•´åˆåˆ° Orchestrator

**ä¿®æ”¹æª”æ¡ˆ**ï¼š`src/lib/agents/orchestrator.ts`

**ä½ç½® 1**ï¼šé ‚éƒ¨ importï¼ˆç´„ Line 1-20ï¼‰

```typescript
// åŠ å…¥é€™ä¸€è¡Œ
import { MultiAgentOutputAdapter } from "./output-adapter";
```

**ä½ç½® 2**ï¼š`executeContentGeneration` æ–¹æ³•çµå°¾ï¼ˆç´„ Line 200-210ï¼‰

æ‰¾åˆ°é€™æ®µç¨‹å¼ç¢¼ï¼š

```typescript
const assemblerOutput = await contentAssembler.execute({
  title,
  introduction,
  sections,
  conclusion,
  qa,
});

return assemblerOutput; // â† ä¿®æ”¹é€™è£¡
```

æ”¹ç‚ºï¼š

```typescript
const assemblerOutput = await contentAssembler.execute({
  title,
  introduction,
  sections,
  conclusion,
  qa,
});

// æ–°å¢ï¼šæ ¼å¼è½‰æ›
try {
  const adapter = new MultiAgentOutputAdapter();
  const writingOutput = adapter.adapt({
    assemblerOutput,
    strategyOutput,
    focusKeyword: input.focusKeyphrase || strategyOutput.selectedTitle,
  });

  console.log("[Orchestrator] âœ… Output adapter successfully converted format");
  return writingOutput;
} catch (adapterError) {
  console.error("[Orchestrator] âŒ Output adapter failed:", adapterError);
  // Fallback: æ‹‹å‡ºéŒ¯èª¤ï¼Œè®“ä¸Šå±¤è™•ç†
  throw adapterError;
}
```

**æª¢æŸ¥æ¸…å–®**ï¼š

- [ ] import å·²åŠ å…¥
- [ ] æ ¼å¼è½‰æ›é‚è¼¯å·²åŠ å…¥
- [ ] TypeScript ç„¡éŒ¯èª¤
- [ ] `npm run build` æˆåŠŸ

---

#### Step 1.4: ArticleStorage é©—è­‰å¼·åŒ–

**ä¿®æ”¹æª”æ¡ˆ**ï¼š`src/lib/services/article-storage.ts`

**ä½ç½® 1**ï¼šå»ºç«‹ ValidationError é¡åˆ¥ï¼ˆæª”æ¡ˆé–‹é ­ï¼‰

```typescript
export class ValidationError extends Error {
  constructor(message: string) {
    super(message);
    this.name = "ValidationError";
  }
}
```

**ä½ç½® 2**ï¼šä¿®æ”¹ `saveArticle` æ–¹æ³•ï¼ˆç´„ Line 32ï¼‰

```typescript
async saveArticle(params: SaveArticleParams): Promise<SavedArticle> {
  const { articleJobId, result, websiteId, companyId, userId } = params;

  // æ–°å¢ï¼šé©—è­‰å¿…è¦æ¬„ä½
  this.validateInput(result);

  // åŸæœ‰çš„å„²å­˜é‚è¼¯...
  if (!result.writing || !result.meta) {
    throw new Error('æ–‡ç« å…§å®¹æˆ– Metadata ä¸å®Œæ•´');
  }

  // ... å…¶é¤˜ä¸è®Š
}
```

**ä½ç½® 3**ï¼šåŠ å…¥é©—è­‰æ–¹æ³•ï¼ˆé¡åˆ¥çµå°¾ï¼‰

```typescript
private validateInput(result: ArticleGenerationResult): void {
  // æª¢æŸ¥å¿…è¦æ¬„ä½å­˜åœ¨
  if (!result.writing) {
    throw new ValidationError('Missing required field: result.writing');
  }

  if (!result.meta) {
    throw new ValidationError('Missing required field: result.meta');
  }

  // æª¢æŸ¥ writing å­æ¬„ä½
  const requiredFields = [
    'markdown',
    'html',
    'statistics',
    'readability',
    'keywordUsage',
    'internalLinks',
  ];

  for (const field of requiredFields) {
    if (!result.writing[field]) {
      throw new ValidationError(`Missing required field: result.writing.${field}`);
    }
  }

  // æª¢æŸ¥è³‡æ–™é¡å‹
  this.validateTypes(result);

  // æª¢æŸ¥æ•¸å€¼ç¯„åœ
  this.validateRanges(result);
}

private validateTypes(result: ArticleGenerationResult): void {
  const { writing } = result;

  if (typeof writing.statistics.wordCount !== 'number') {
    throw new ValidationError('Invalid type for wordCount: expected number');
  }

  if (typeof writing.readability.fleschReadingEase !== 'number') {
    throw new ValidationError('Invalid type for fleschReadingEase: expected number');
  }

  if (typeof writing.readability.fleschKincaidGrade !== 'number') {
    throw new ValidationError('Invalid type for fleschKincaidGrade: expected number');
  }

  if (typeof writing.readability.gunningFogIndex !== 'number') {
    throw new ValidationError('Invalid type for gunningFogIndex: expected number');
  }

  if (typeof writing.keywordUsage.density !== 'number') {
    throw new ValidationError('Invalid type for keywordUsage.density: expected number');
  }

  if (typeof writing.keywordUsage.count !== 'number') {
    throw new ValidationError('Invalid type for keywordUsage.count: expected number');
  }

  if (!Array.isArray(writing.internalLinks)) {
    throw new ValidationError('Invalid type for internalLinks: expected array');
  }
}

private validateRanges(result: ArticleGenerationResult): void {
  const { writing } = result;

  // wordCount ç¯„åœæª¢æŸ¥
  if (writing.statistics.wordCount <= 0 || writing.statistics.wordCount > 100000) {
    throw new ValidationError(
      `Value out of range for wordCount: ${writing.statistics.wordCount} (expected 1-100000)`
    );
  }

  // fleschReadingEase ç¯„åœæª¢æŸ¥
  if (
    writing.readability.fleschReadingEase < 0 ||
    writing.readability.fleschReadingEase > 100
  ) {
    throw new ValidationError(
      `Value out of range for fleschReadingEase: ${writing.readability.fleschReadingEase} (expected 0-100)`
    );
  }

  // density ç¯„åœæª¢æŸ¥
  if (writing.keywordUsage.density < 0 || writing.keywordUsage.density > 100) {
    throw new ValidationError(
      `Value out of range for density: ${writing.keywordUsage.density} (expected 0-100)`
    );
  }
}
```

**æª¢æŸ¥æ¸…å–®**ï¼š

- [ ] ValidationError é¡åˆ¥å·²åŠ å…¥
- [ ] validateInput æ–¹æ³•å·²åŠ å…¥
- [ ] validateTypes æ–¹æ³•å·²åŠ å…¥
- [ ] validateRanges æ–¹æ³•å·²åŠ å…¥
- [ ] TypeScript ç„¡éŒ¯èª¤
- [ ] `npm run build` æˆåŠŸ

---

**Phase 1 æ¸¬è©¦**ï¼š

```bash
# 1. å»ºç½®æª¢æŸ¥
npm run build

# 2. é¡å‹æª¢æŸ¥
npm run typecheck

# 3. Lint æª¢æŸ¥
npm run lint

# 4. è§¸ç™¼ä¸€æ¬¡æ–‡ç« ç”Ÿæˆï¼ˆé€é UI æˆ– APIï¼‰
# 5. æª¢æŸ¥ generated_articles æ˜¯å¦æœ‰æ–°è¨˜éŒ„
# 6. æª¢æŸ¥æ‰€æœ‰æ¬„ä½æ˜¯å¦éƒ½æœ‰å€¼
```

---

### Phase 2: éŒ¯èª¤è¿½è¹¤ï¼ˆDay 3ï¼‰

#### Step 2.1: å¼·åŒ– Error Tracker

**ä¿®æ”¹æª”æ¡ˆ**ï¼š`src/lib/agents/error-tracker.ts`

æ‰¾åˆ° `constructor` ä¸¦ä¿®æ”¹ï¼š

```typescript
constructor(
  private articleJobId: string,
  private supabase: SupabaseClient  // æ–°å¢é€™å€‹åƒæ•¸
) {
  this.errors = [];
}
```

åœ¨é¡åˆ¥ä¸­åŠ å…¥æ–°æ–¹æ³•ï¼š

```typescript
async trackError(error: TrackedError): Promise<void> {
  // åŸæœ‰çš„è¨˜æ†¶é«”è¿½è¹¤
  this.errors.push(error);

  // æ–°å¢ï¼šå¯«å…¥è³‡æ–™åº«
  await this.saveToDatabase(error);
}

private async saveToDatabase(error: TrackedError): Promise<void> {
  try {
    // 1. è®€å–ç¾æœ‰çš„ metadata
    const { data: job } = await this.supabase
      .from('article_generation_jobs')
      .select('metadata')
      .eq('id', this.articleJobId)
      .single();

    const metadata = (job?.metadata as Record<string, any>) || {};
    const existingErrors = metadata.errors || [];

    // 2. æ–°å¢éŒ¯èª¤ï¼ˆåªä¿ç•™æœ€æ–° 10 å€‹ï¼‰
    const updatedErrors = [
      ...existingErrors,
      {
        id: crypto.randomUUID(),
        timestamp: new Date().toISOString(),
        agent: error.agent,
        phase: error.phase,
        message: error.error,
        context: error.context,
      },
    ].slice(-10);

    // 3. æ›´æ–° metadata
    await this.supabase
      .from('article_generation_jobs')
      .update({
        metadata: {
          ...metadata,
          errors: updatedErrors,
          lastError: {
            timestamp: new Date().toISOString(),
            message: error.error,
          },
        },
      })
      .eq('id', this.articleJobId);

    console.log(`[ErrorTracker] âœ… Error saved to database: ${error.agent}`);
  } catch (dbError) {
    console.error('[ErrorTracker] âŒ Failed to save error to database:', dbError);
  }
}

generateSummary(): string {
  if (this.errors.length === 0) {
    return 'No errors occurred';
  }

  const summary = [`Total errors: ${this.errors.length}`, '', 'Error breakdown:'];

  // æŒ‰ agent åˆ†çµ„
  const groupedByAgent = this.errors.reduce((acc, error) => {
    if (!acc[error.agent]) {
      acc[error.agent] = [];
    }
    acc[error.agent].push(error);
    return acc;
  }, {} as Record<string, TrackedError[]>);

  for (const [agent, errors] of Object.entries(groupedByAgent)) {
    summary.push(`- ${agent}: ${errors.length} error(s)`);
    errors.forEach(err => {
      summary.push(`  - ${err.error}`);
    });
  }

  return summary.join('\n');
}
```

**æª¢æŸ¥æ¸…å–®**ï¼š

- [ ] constructor åƒæ•¸å·²æ›´æ–°
- [ ] saveToDatabase æ–¹æ³•å·²åŠ å…¥
- [ ] generateSummary æ–¹æ³•å·²åŠ å…¥
- [ ] TypeScript ç„¡éŒ¯èª¤

---

#### Step 2.2: æ›´æ–° Orchestrator éŒ¯èª¤è¿½è¹¤

**ä¿®æ”¹æª”æ¡ˆ**ï¼š`src/lib/agents/orchestrator.ts`

æ‰¾åˆ°å»ºç«‹ ErrorTracker çš„åœ°æ–¹ï¼ˆç´„ Line 100-150ï¼‰ï¼Œç¢ºä¿å‚³å…¥ `supabase`ï¼š

```typescript
this.errorTracker = new ErrorTracker(
  input.articleJobId,
  this.supabase, // ç¢ºä¿æœ‰é€™å€‹åƒæ•¸
);
```

æ‰¾åˆ°æ‰€æœ‰ Agent åŸ·è¡Œçš„åœ°æ–¹ï¼ŒåŠ å…¥éŒ¯èª¤è¿½è¹¤ã€‚ä¾‹å¦‚ IntroductionAgentï¼š

```typescript
// Introduction Agent åŸ·è¡Œ
try {
  const introduction = await introAgent.execute(...);
  await this.updateJobStatus('introduction_completed', { introduction });
} catch (error) {
  await this.errorTracker.trackError({
    agent: 'IntroductionAgent',
    phase: 'content_generation',
    error: error instanceof Error ? error.message : String(error),
    context: {
      retryCount: this.retryCount || 0,
      focusKeyphrase: input.focusKeyphrase,
    },
  });
  throw error;
}
```

å°æ‰€æœ‰ Agent éƒ½åŠ å…¥é¡ä¼¼çš„éŒ¯èª¤è¿½è¹¤ï¼š

- IntroductionAgent
- SectionAgent (æ¯å€‹ section)
- ConclusionAgent
- QAAgent
- ContentAssemblerAgent

æœ€å¾Œï¼Œåœ¨æœ€çµ‚å¤±æ•—è™•ç†åŠ å…¥æ‘˜è¦ï¼š

```typescript
} catch (finalError) {
  console.error('[Orchestrator] âŒ Final failure:', finalError);

  const errorSummary = this.errorTracker.generateSummary();

  await this.supabase
    .from('article_generation_jobs')
    .update({
      status: 'failed',
      error_message: errorSummary,
    })
    .eq('id', this.articleJobId);

  throw finalError;
}
```

**æª¢æŸ¥æ¸…å–®**ï¼š

- [ ] ErrorTracker å»ºæ§‹æ™‚å‚³å…¥ supabase
- [ ] æ‰€æœ‰ Agent åŸ·è¡Œéƒ½æœ‰éŒ¯èª¤è¿½è¹¤
- [ ] æœ€çµ‚å¤±æ•—æ™‚ç”Ÿæˆæ‘˜è¦
- [ ] TypeScript ç„¡éŒ¯èª¤

---

### Phase 3: ç›£æ§ç³»çµ±ï¼ˆDay 4ï¼‰

#### Step 3.1: å»ºç«‹ç›£æ§ API Endpoint

**å»ºç«‹æª”æ¡ˆ**ï¼š`src/app/api/cron/monitor-article-jobs/route.ts`

```typescript
import { NextRequest, NextResponse } from "next/server";
import { createClient } from "@/lib/supabase/server";

export async function POST(request: NextRequest) {
  try {
    // 1. é©—è­‰è«‹æ±‚ä¾†æº
    const authHeader = request.headers.get("authorization");
    const token = authHeader?.replace("Bearer ", "");

    if (token !== process.env.CRON_API_SECRET) {
      console.log("[Monitor] âŒ Unauthorized request");
      return NextResponse.json({ error: "Unauthorized" }, { status: 401 });
    }

    console.log("[Monitor] âœ… Request authorized");

    // 2. é€£æ¥è³‡æ–™åº«
    const supabase = await createClient();

    // 3. æŸ¥è©¢æ‰€æœ‰ processing jobs
    const { data: jobs, error } = await supabase
      .from("article_generation_jobs")
      .select("*")
      .eq("status", "processing");

    if (error) {
      console.error("[Monitor] âŒ Database query failed:", error);
      return NextResponse.json({ error: "Database error" }, { status: 500 });
    }

    if (!jobs || jobs.length === 0) {
      console.log("[Monitor] â„¹ï¸ No processing jobs found");
      return NextResponse.json({ processed: 0 });
    }

    console.log(`[Monitor] ğŸ“Š Found ${jobs.length} processing jobs`);

    const results = {
      processed: 0,
      timeout: 0,
      stuck: 0,
      retried: 0,
    };

    // 4. æª¢æŸ¥æ¯å€‹ job
    for (const job of jobs) {
      const createdAt = new Date(job.created_at);
      const updatedAt = new Date(job.updated_at);
      const now = new Date();

      const totalDuration = (now.getTime() - createdAt.getTime()) / 1000 / 60; // åˆ†é˜
      const phaseDuration = (now.getTime() - updatedAt.getTime()) / 1000 / 60; // åˆ†é˜

      // æª¢æŸ¥è¶…æ™‚ï¼ˆ> 30 åˆ†é˜ï¼‰
      if (totalDuration > 30) {
        console.log(
          `[Monitor] â° Job ${job.id} timeout (${totalDuration.toFixed(1)}min)`,
        );

        const metadata = (job.metadata as Record<string, any>) || {};
        const retryCount = metadata.retry_count || 0;

        if (retryCount < 1) {
          // ç¬¬ä¸€æ¬¡å¤±æ•—ï¼šé‡è©¦
          await supabase
            .from("article_generation_jobs")
            .update({
              status: "failed",
              error_message: `Timeout after ${totalDuration.toFixed(1)} minutes`,
              metadata: {
                ...metadata,
                retry_count: retryCount + 1,
                retry_reason: "timeout",
              },
            })
            .eq("id", job.id);

          results.retried++;
          console.log(`[Monitor] ğŸ”„ Marked for retry: ${job.id}`);
        } else {
          // ç¬¬äºŒæ¬¡å¤±æ•—ï¼šæ°¸ä¹…å¤±æ•—
          await supabase
            .from("article_generation_jobs")
            .update({
              status: "failed",
              error_message: `Permanent failure after ${retryCount + 1} attempts`,
            })
            .eq("id", job.id);

          console.log(`[Monitor] âŒ Permanent failure: ${job.id}`);
        }

        results.timeout++;
        results.processed++;
        continue;
      }

      // æª¢æŸ¥å¡ä½ï¼ˆ> 10 åˆ†é˜æ²’æ›´æ–°ï¼‰
      if (phaseDuration > 10) {
        console.log(
          `[Monitor] âš ï¸ Job ${job.id} stuck at ${job.current_phase} (${phaseDuration.toFixed(1)}min)`,
        );

        // TODO: å¯¦ä½œå¾è©²éšæ®µæ¢å¾©çš„é‚è¼¯
        // await resumeFromPhase(job);

        results.stuck++;
        results.processed++;
        continue;
      }
    }

    console.log(`[Monitor] âœ… Monitoring complete:`, results);

    return NextResponse.json(results);
  } catch (error) {
    console.error("[Monitor] âŒ Monitoring failed:", error);
    return NextResponse.json(
      {
        error: "Internal server error",
        message: error instanceof Error ? error.message : String(error),
      },
      { status: 500 },
    );
  }
}
```

**æª¢æŸ¥æ¸…å–®**ï¼š

- [ ] æª”æ¡ˆå»ºç«‹å®Œæˆ
- [ ] é©—è­‰é‚è¼¯å·²å¯¦ä½œ
- [ ] è¶…æ™‚æª¢æ¸¬å·²å¯¦ä½œ
- [ ] TypeScript ç„¡éŒ¯èª¤

---

#### Step 3.2: å»ºç«‹ GitHub Actions Workflow

**å»ºç«‹æª”æ¡ˆ**ï¼š`.github/workflows/monitor-article-jobs.yml`

```yaml
name: Monitor Article Jobs

on:
  schedule:
    - cron: "*/5 * * * *" # æ¯ 5 åˆ†é˜åŸ·è¡Œä¸€æ¬¡
  workflow_dispatch: # å…è¨±æ‰‹å‹•è§¸ç™¼

jobs:
  monitor:
    runs-on: ubuntu-latest
    steps:
      - name: Call Monitoring API
        run: |
          echo "ğŸš€ Calling monitoring API..."

          response=$(curl -s -w "\n%{http_code}" -X POST \
            -H "Authorization: Bearer ${{ secrets.CRON_API_SECRET }}" \
            -H "Content-Type: application/json" \
            "${{ secrets.APP_URL }}/api/cron/monitor-article-jobs")

          http_code=$(echo "$response" | tail -n1)
          body=$(echo "$response" | sed '$d')

          echo "ğŸ“Š HTTP Status: $http_code"
          echo "ğŸ“„ Response: $body"

          if [ "$http_code" != "200" ]; then
            echo "âŒ Monitoring failed"
            exit 1
          fi

          echo "âœ… Monitoring completed successfully"
```

**æª¢æŸ¥æ¸…å–®**ï¼š

- [ ] æª”æ¡ˆå»ºç«‹å®Œæˆ
- [ ] Cron schedule æ­£ç¢ºï¼ˆæ¯ 5 åˆ†é˜ï¼‰
- [ ] workflow_dispatch å·²è¨­å®š

---

#### Step 3.3: è¨­å®šç’°å¢ƒè®Šæ•¸

**æœ¬åœ°ç’°å¢ƒ**ï¼ˆ`.env.local`ï¼‰ï¼š

```bash
# ç”Ÿæˆéš¨æ©Ÿ secret
CRON_API_SECRET=$(openssl rand -hex 32)

# åŠ å…¥åˆ° .env.local
echo "CRON_API_SECRET=$CRON_API_SECRET" >> .env.local
```

**GitHub Secrets**ï¼š

1. å‰å¾€ GitHub repository
2. Settings â†’ Secrets and variables â†’ Actions
3. æ–°å¢ secretsï¼š
   - `CRON_API_SECRET`ï¼šèˆ‡ `.env.local` ç›¸åŒçš„å€¼
   - `APP_URL`ï¼šä½ çš„æ‡‰ç”¨ç¨‹å¼ URLï¼ˆä¾‹å¦‚ï¼š`https://your-app.vercel.app`ï¼‰

**Vercel ç’°å¢ƒè®Šæ•¸**ï¼š

```bash
# ä½¿ç”¨ Vercel CLI è¨­å®š
vercel env add CRON_API_SECRET production
# è²¼ä¸Šèˆ‡ .env.local ç›¸åŒçš„å€¼
```

**æª¢æŸ¥æ¸…å–®**ï¼š

- [ ] æœ¬åœ° `.env.local` å·²è¨­å®š `CRON_API_SECRET`
- [ ] GitHub Secrets å·²è¨­å®š `CRON_API_SECRET` å’Œ `APP_URL`
- [ ] Vercel ç’°å¢ƒè®Šæ•¸å·²è¨­å®š `CRON_API_SECRET`

---

### Phase 4: æ¸¬è©¦é©—è­‰ï¼ˆDay 5ï¼‰

#### Test 1: ç«¯åˆ°ç«¯æ¸¬è©¦

```bash
# 1. å»ºç½®æª¢æŸ¥
npm run build

# 2. è§¸ç™¼ä¸€æ¬¡æ–‡ç« ç”Ÿæˆ
# é€é UI æˆ– API è§¸ç™¼

# 3. ç­‰å¾…å®Œæˆï¼Œæª¢æŸ¥è³‡æ–™åº«
psql $DATABASE_URL << EOF
SELECT
  id,
  status,
  current_phase,
  error_message,
  (metadata->>'errors') as has_errors
FROM article_generation_jobs
ORDER BY created_at DESC
LIMIT 5;

SELECT id, title, word_count, flesch_reading_ease, keyword_density
FROM generated_articles
ORDER BY created_at DESC
LIMIT 1;
EOF
```

**é©—è­‰é …ç›®**ï¼š

- [ ] æ–‡ç« æˆåŠŸå„²å­˜åˆ° `generated_articles`
- [ ] æ‰€æœ‰æ¬„ä½éƒ½æœ‰å€¼ï¼ˆç„¡ nullï¼‰
- [ ] `flesch_reading_ease` åœ¨ 0-100 ç¯„åœå…§
- [ ] `keyword_density` > 0

---

#### Test 2: æ‰‹å‹•è§¸ç™¼ç›£æ§

```bash
# æ‰‹å‹•å‘¼å«ç›£æ§ API
curl -X POST \
  -H "Authorization: Bearer $CRON_API_SECRET" \
  -H "Content-Type: application/json" \
  http://localhost:3000/api/cron/monitor-article-jobs
```

**é æœŸè¼¸å‡º**ï¼š

```json
{
  "processed": 0,
  "timeout": 0,
  "stuck": 0,
  "retried": 0
}
```

**æª¢æŸ¥æ¸…å–®**ï¼š

- [ ] API å›å‚³ 200 ç‹€æ…‹ç¢¼
- [ ] æœªæˆæ¬Šè«‹æ±‚å›å‚³ 401
- [ ] å›å‚³æ ¼å¼æ­£ç¢º

---

#### Test 3: GitHub Actions æ¸¬è©¦

1. å‰å¾€ GitHub repository
2. Actions â†’ Monitor Article Jobs
3. é»æ“Š "Run workflow"
4. æŸ¥çœ‹åŸ·è¡Œæ—¥èªŒ

**æª¢æŸ¥æ¸…å–®**ï¼š

- [ ] Workflow æˆåŠŸåŸ·è¡Œ
- [ ] API å‘¼å«æˆåŠŸï¼ˆHTTP 200ï¼‰
- [ ] æ—¥èªŒæ¸…æ™°å®Œæ•´

---

### Phase 5: éƒ¨ç½²ï¼ˆDay 6ï¼‰

#### Deployment Checklist

**éƒ¨ç½²å‰æª¢æŸ¥**ï¼š

- [ ] `npm run build` æˆåŠŸ
- [ ] `npm run typecheck` ç„¡éŒ¯èª¤
- [ ] `npm run lint` ç„¡éŒ¯èª¤
- [ ] æ‰€æœ‰æ¸¬è©¦é€šé

**Commit å’Œ Push**ï¼š

```bash
git add .
git commit -m "å¯¦ä½œ: ä¿®å¾©å¤š Agent æ¶æ§‹çš„æ–‡ç« å„²å­˜å’ŒéŒ¯èª¤è¿½è¹¤

- æ–°å¢ MultiAgentOutputAdapter è½‰æ›æ ¼å¼
- å¼·åŒ– ErrorTracker è³‡æ–™åº«å¯«å…¥
- å¯¦ä½œ GitHub Actions ç›£æ§
- å®Œå–„è¼¸å…¥é©—è­‰

ğŸ¤– Generated with Claude Code
Co-Authored-By: Claude <noreply@anthropic.com>"

git push origin main
```

**ç­‰å¾… Vercel éƒ¨ç½²**ï¼š

```bash
# ç­‰å¾… 90 ç§’
sleep 90

# æª¢æŸ¥éƒ¨ç½²ç‹€æ…‹
vercel ls | head -8
```

**é©—è­‰éƒ¨ç½²**ï¼š

```bash
# 1. æ¸¬è©¦é¦–é 
curl -I https://your-app.vercel.app

# 2. æ¸¬è©¦ç›£æ§ APIï¼ˆæ‡‰è©²å›å‚³ 401ï¼‰
curl -I https://your-app.vercel.app/api/cron/monitor-article-jobs

# 3. æ¸¬è©¦æˆæ¬Šè«‹æ±‚
curl -X POST \
  -H "Authorization: Bearer $CRON_API_SECRET" \
  https://your-app.vercel.app/api/cron/monitor-article-jobs
```

---

## ğŸ“Š æœ€çµ‚é©—æ”¶

åœ¨æ¨™è¨˜ç‚ºå®Œæˆå‰ï¼Œç¢ºèªï¼š

- [ ] âœ… æ–‡ç« å„²å­˜æˆåŠŸç‡ = 100%
- [ ] âœ… æ‰€æœ‰æ¬„ä½éƒ½æœ‰å€¼ï¼ˆç„¡ nullï¼‰
- [ ] âœ… éŒ¯èª¤éƒ½è¨˜éŒ„åˆ° metadata.errors
- [ ] âœ… GitHub Actions æ¯ 5 åˆ†é˜åŸ·è¡Œ
- [ ] âœ… ç›£æ§ API æ­£å¸¸é‹ä½œ
- [ ] âœ… Production éƒ¨ç½²æˆåŠŸ

---

## ğŸ†˜ å¸¸è¦‹å•é¡Œ

### Q1: TypeScript éŒ¯èª¤ "Property 'readability' does not exist"

**è§£æ±ºæ–¹æ¡ˆ**ï¼šç¢ºèªå‹åˆ¥å®šç¾©å·²æ›´æ–°åˆ° `src/types/agents.ts`

### Q2: æ–‡ç« å„²å­˜æ™‚å‡ºç¾ ValidationError

**è§£æ±ºæ–¹æ¡ˆ**ï¼šæª¢æŸ¥ Output Adapter æ˜¯å¦æ­£ç¢ºåŸ·è¡Œï¼ŒæŸ¥çœ‹ console.log

### Q3: GitHub Actions å›å‚³ 401

**è§£æ±ºæ–¹æ¡ˆ**ï¼šæª¢æŸ¥ GitHub Secrets æ˜¯å¦æ­£ç¢ºè¨­å®š

### Q4: ç›£æ§ API æ²’æœ‰è™•ç†ä»»ä½• jobs

**è§£æ±ºæ–¹æ¡ˆ**ï¼šæ­£å¸¸ç¾è±¡ï¼Œä»£è¡¨æ²’æœ‰ processing çš„ jobs

---

## ğŸ“ éœ€è¦å”åŠ©ï¼Ÿ

å¦‚æœ‰ä»»ä½•å•é¡Œï¼Œè«‹æŸ¥çœ‹ï¼š

- OpenSpec ææ¡ˆï¼š`openspec/changes/fix-multi-agent-storage-and-errors/proposal.md`
- è¨­è¨ˆæ–‡ä»¶ï¼š`openspec/changes/fix-multi-agent-storage-and-errors/design.md`
- è©³ç´°ä»»å‹™ï¼š`openspec/changes/fix-multi-agent-storage-and-errors/tasks.md`

ç¥å¯¦ä½œé †åˆ©ï¼ğŸš€
